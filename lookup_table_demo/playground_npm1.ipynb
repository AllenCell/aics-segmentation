{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playground 3:  Segmentation workflow for Nucleophosmin\n",
    "\n",
    "This notebook contains the workflow for Nucleophosmin, and serves as a starting point for developing a classic segmentation workflow if your data shows similar morphology as Nucleophosmin.\n",
    "\n",
    "----------------------------------------\n",
    "\n",
    "Cell Structure Observations:\n",
    "\n",
    "* [Nucleophosmin](https://www.allencell.org/cell-observations/category/nucleophosmin)\n",
    "\n",
    "----------------------------------------\n",
    "\n",
    "Key steps of the workflows:\n",
    "\n",
    "* Auto-Contrast intensity normalization\n",
    "* 3D Gaussian smoothing (slice-by-slice)\n",
    "* Masked-object Thresholding\n",
    "* 2D spot filters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# package for 3d visualization\n",
    "from itkwidgets import view                              \n",
    "from aicssegmentation.core.visual import seg_fluo_side_by_side,  single_fluorescent_view, segmentation_quick_view\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = [16, 12]\n",
    "\n",
    "# package for io \n",
    "from aicsimageio import AICSImage\n",
    "from aicsimageio.writers import OmeTiffWriter\n",
    "\n",
    "# function for core algorithm\n",
    "from scipy.ndimage.morphology import binary_fill_holes\n",
    "from aicssegmentation.core.seg_dot import dot_2d_slice_by_slice_wrapper\n",
    "from aicssegmentation.core.pre_processing_utils import intensity_normalization, image_smoothing_gaussian_3d\n",
    "from skimage.morphology import remove_small_objects, binary_closing, ball, disk, erosion, dilation   # function for post-processing (size filter)\n",
    "from aicssegmentation.core.MO_threshold import MO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_NAME = '../../data/NPM1/original/3500001991_100X_20180430_1-Scene-10-P10-E04.czi'\n",
    "reader = AICSImage(FILE_NAME) \n",
    "IMG = reader.data.astype(np.float32)\n",
    "\n",
    "print(IMG.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preview of the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_CHANNELS = IMG.shape[2]\n",
    "MID_SLICE = np.int(0.5*IMG.shape[3])\n",
    "\n",
    "fig, ax = plt.subplots(1, N_CHANNELS, figsize=(18,16), dpi=72, facecolor='w', edgecolor='k')\n",
    "if N_CHANNELS==1:\n",
    "    ax.axis('off')\n",
    "    ax.imshow(IMG[0,0,0,MID_SLICE,:,:], cmap=plt.cm.gray)\n",
    "else:\n",
    "    for channel in range(N_CHANNELS):\n",
    "        ax[channel].axis('off')\n",
    "        ax[channel].imshow(IMG[0,0,channel,MID_SLICE,:,:], cmap=plt.cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################\n",
    "structure_channel = 3\n",
    "#####################\n",
    "\n",
    "struct_img0 = IMG[0,0,structure_channel,:,:,:].copy()\n",
    "view(single_fluorescent_view(struct_img0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Pre-Processing\n",
    "\n",
    "About selected algorithms and tuned parameters\n",
    "\n",
    "* **Intensity normalization**: Parameter `intensity_scaling_param` has two options: two values, say `[A, B]`, or single value, say `[K]`. For the first case, `A` and `B` are non-negative values indicating that the full intensity range of the stack will first be cut-off into **[mean - A * std, mean + B * std]** and then rescaled to **[0, 1]**. The smaller the values of `A` and `B` are, the higher the contrast will be. For the second case, `K`>0 indicates min-max Normalization with an absolute intensity upper bound `K` (i.e., anything above `K` will be chopped off and reset as the minimum intensity of the stack) and `K`=0 means min-max Normalization without any intensity bound.\n",
    "\n",
    "    * Parameter for NPM1:  `intensity_scaling_param = [0.5, 15]`\n",
    "\n",
    "\n",
    "* **Smoothing** \n",
    "\n",
    "    3D gaussian smoothing with `gaussian_smoothing_sigma = 1`. The large the value is, the more the image will be smoothed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "## PARAMETERS for this step ##\n",
    "intensity_scaling_param = [0.5, 15]\n",
    "gaussian_smoothing_sigma = 1\n",
    "################################\n",
    "# intensity normalization\n",
    "struct_img = intensity_normalization(struct_img0, scaling_param=intensity_scaling_param)\n",
    "\n",
    "# smoothing with gaussian filter\n",
    "structure_img_smooth = image_smoothing_gaussian_3d(struct_img, sigma=gaussian_smoothing_sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view(single_fluorescent_view(structure_img_smooth))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If the contrast looks too off, you can tune the normalization parameters.\n",
    "\n",
    "We have a function to give you some suggestions. If you have certain preference, you can adjust the values based on the suggestion.\n",
    "\n",
    "***After you decide the parameters, you have to re-run the code above with the new parameter*** `intensity_scaling_param = `#### If the contrast looks too off, you can play with the normalization parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aicssegmentation.core.pre_processing_utils import suggest_normalization_param\n",
    "suggest_normalization_param(struct_img0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Core Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### step 2.1: Masked-Object (MO) Thresholding\n",
    "\n",
    "The basic idea of MO thresholding is to apply a relatively low global threshold to roughly mask out each individual object, and then apply a relatively high threshold within each object. This is meant to handle intensity variation from cell to cell. In general, triangle method and median method are two thresholding algorithms usually yield relatively low threshold. Otsu is used within each object for the relatively high threshold. \n",
    "\n",
    "There are two parameters:\n",
    "* `global_thresh_method`: Support `'tri'`, `'med'`,`'ave'` in current version. `'tri'` is triangle method, `'med'` is median method, `'ave'` is the average of the values returned by triangle method and median method.\n",
    "* `object_minArea`: The minimal area of connected components after global thresholding to be considered as valid objects. Due to some background noise there could be some small connected components in the global thresholding result. Doing Otsu thresholding within such regions will certainly result in errors. So, we want remove them before doing thresholding within each object.  \n",
    "\n",
    "\n",
    "Parameter for NPM1:  `global_thresh_method='ave'` and `object_minArea=700`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bw, object_for_debug = MO(structure_img_smooth, global_thresh_method='ave', object_minArea=700, return_object=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view the segmentation result\n",
    "viewer_bw = view(segmentation_quick_view(bw))\n",
    "viewer_bw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### After quickly visualizing the segmentation results, you can also visualize the segmentation and original image side by side\n",
    "##### You may select an ROI to inspect the details\n",
    "\n",
    "* Option 1: Easy ROI selection, but NOT recommended if you are using a laptop\n",
    "\n",
    "You can select an ROI in above visualization ('viewer_bw'); otherwise, the default ROI is the full image\n",
    "\n",
    "[See this video for How to select ROI](https://www.youtube.com/watch?v=ZO8ey6-tF_0&index=3&list=PL2lHcsoU0YJsh6f8j2vbhg2eEpUnKEWcl)\n",
    "\n",
    "* Option 2: Manually type in ROI coordinates\n",
    "\n",
    "Type in the coordinates of upper left corner and lower right corner of the ROI in the form of [Upper_Left_X, Upper_Left_Y, Lower_right_X, Lower_right_Y]. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1:\n",
    "view(seg_fluo_side_by_side(struct_img,bw,roi=['ROI',viewer_bw.roi_slice()]))\n",
    "\n",
    "# Option 2: \n",
    "# view(seg_fluo_side_by_side(struct_img,bw,roi=['M',[570,370,730,440]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### If the above segmentation is satisfactory? Here are some possible things to check:\n",
    "* Is there big missing chunk? Or are segmented chunks are significantly fatter? You may visualize the intermediate result, i.e. the objects, by `view(segmentation_quick_view(object_for_debug))`. By doing this, you can have some sense whether the objects are roughly regions in individual cells. In other words, we want to roughly isolate the stuffs in individual cells. If not, you may change `global_thresh_method`. Three options `'tri'`, `'med'`,`'ave'` are implemented. `'tri'` is triangle method, `'med'` is median method, `'ave'` is the average of the values returned by triangle method and median method. \n",
    "* Observing missing chunks may be also due to falsely removed objects. Try to decrease `object_minArea` to be more permisive in segmenting objects.\n",
    "* Do you observe a chunk of background stuffs in the segmentation? Try to increase `object_minArea` to exclude these background noise. \n",
    "* If you observe the segmented objects are slightly fatter than the actual size (may take defraction of light into consideration), don't worry, Next step (2.2) can help the make them thinner. \n",
    "* If you observe missing dots in the segmentation, don't worry. Later step (2.3) can pick them up.\n",
    "\n",
    "\n",
    "#### If the results are satisfactory, go to step 2.2; otherwise, try to tweak the parameters based on the above suggestions. \n",
    "\n",
    "Assumption: the segmentation result is saved in a variable named `bw`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### step 2.2: Apply 2D spot filte \n",
    "\n",
    "Parameter syntax: `[[scale_1, cutoff_1], [scale_2, cutoff_2], ....]` \n",
    "* `scale_x` is set based on the estimated radius of your target dots. For example, if visually the diameter of the dots is usually 3~4 pixels, then you may want to set `scale_x` as `1` or something near `1` (like `1.25`). Multiple scales can be used, if you have dots of very different sizes.  \n",
    "* `cutoff_x` is a threshold applied on the actual filter reponse to get the binary result. Smaller `cutoff_x` may yielf more dots and fatter segmentation, while larger `cutoff_x` could be less permisive and yield less dots and slimmer segmentation. \n",
    "\n",
    "We want to apply S2 filter in two ways: one on the original image to detect extra bright spots, and another one on the inverse of the original image to detect dark spots to remove\n",
    "\n",
    "Parameter for extra bright spots:  `s2_param_bright = [[2, 0.025]]`\n",
    "Parameter for dark spots:  `s2_param_dark = [[2, 0.025], [1, 0.025]]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######\n",
    "s2_param_bright = [[2, 0.025]]\n",
    "s2_param_dark = [[2, 0.025], [1, 0.025]]\n",
    "######\n",
    "\n",
    "bw_extra = dot_2d_slice_by_slice_wrapper(structure_img_smooth, s2_param_bright)\n",
    "bw_dark = dot_2d_slice_by_slice_wrapper(1-structure_img_smooth, s2_param_dark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view(segmentation_quick_view(bw_extra))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view(segmentation_quick_view(bw_dark))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### step 2.3: merge the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bw_merge = np.logical_or(bw, bw_extra)\n",
    "bw_merge[bw_dark>0]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view(segmentation_quick_view(bw_merge))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Post-Processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "## PARAMETERS for this step ##\n",
    "minArea = 10\n",
    "################################\n",
    "\n",
    "seg = remove_small_objects(bw_merge>0, min_size=minArea, connectivity=1, in_place=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view(seg_fluo_side_by_side(struct_img, seg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You can also focus your inspection on a small ROI\n",
    "\n",
    "* Option 1: Easy ROI selection, but NOT recommended if you are using a laptop\n",
    "\n",
    "You can select an ROI in above visualization ('viewer_final'); otherwise, the default ROI is the full image\n",
    "\n",
    "[See this video for How to select ROI](https://www.youtube.com/watch?v=ZO8ey6-tF_0&index=3&list=PL2lHcsoU0YJsh6f8j2vbhg2eEpUnKEWcl)\n",
    "\n",
    "* Option 2: Manually type in ROI coordinates\n",
    "\n",
    "Type in the coordinates of upper left corner and lower right corner of the ROI in the form of [Upper_Left_X, Upper_Left_Y, Lower_right_X, Lower_right_Y]. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: \n",
    "view(seg_fluo_side_by_side(struct_img, seg, roi=['ROI',viewer_final.roi_slice()]))\n",
    "\n",
    "# Option 2: \n",
    "#view(seg_fluo_side_by_side(struct_img, seg, roi=['M',[267,440, 468, 605]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You may also physically save the segmentation results into a ome.tif file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg = seg >0\n",
    "out=seg.astype(np.uint8)\n",
    "out[out>0]=255\n",
    "writer = OmeTiffWriter('../../data/NPM1/result/3500001289_100X_20170915_25_44_1-Scene-11-P39-E08_test_segmentation.tiff')\n",
    "writer.save(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
