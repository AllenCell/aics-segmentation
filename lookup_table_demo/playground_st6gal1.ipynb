{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playground 1:  Segmentation workflow for sialyltransferase 1\n",
    "\n",
    "This notebook contains the workflow for sialyltransferase 1, and serves as a starting point for developing a classic segmentation workflow if your data shows similar morphology as sialyltransferase 1.\n",
    "\n",
    "----------------------------------------\n",
    "\n",
    "Cell Structure Observations:\n",
    "\n",
    "* [Sialyltransferase 1](https://www.allencell.org/cell-observations/category/sialyltransferase-1)\n",
    "\n",
    "----------------------------------------\n",
    "\n",
    "Key steps of the workflows:\n",
    "\n",
    "* Auto-Contrast intensity normalization\n",
    "* 3D Gaussian smoothing \n",
    "* Masked-Object Thresholding \n",
    "* 3D Spot filter \n",
    "* Topology-preserving smoothing\n",
    "* Size thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# package for 3d visualization\n",
    "from itkwidgets import view                              \n",
    "from aicssegmentation.core.visual import seg_fluo_side_by_side,  single_fluorescent_view, segmentation_quick_view\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = [16, 12]\n",
    "\n",
    "# package for io \n",
    "from aicsimageio import AICSImage\n",
    "from aicsimageio.writers import OmeTiffWriter\n",
    "\n",
    "# function for core algorithm\n",
    "from aicssegmentation.core.seg_dot import dot_3d_wrapper\n",
    "from aicssegmentation.core.pre_processing_utils import intensity_normalization, image_smoothing_gaussian_3d\n",
    "from skimage.morphology import remove_small_objects, binary_closing, ball , dilation   # function for post-processing (size filter)\n",
    "from aicssegmentation.core.utils import topology_preserving_thinning\n",
    "from aicssegmentation.core.MO_threshold import MO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_NAME = '../../data/ST6GAL1/original/3500001289_100X_20170915_25_44_1-Scene-11-P39-E08.czi'\n",
    "\n",
    "reader = AICSImage(FILE_NAME) \n",
    "IMG = reader.data.astype(np.float32)\n",
    "\n",
    "print(IMG.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preview of the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_CHANNELS = IMG.shape[2]\n",
    "MID_SLICE = np.int(0.5*IMG.shape[3])\n",
    "\n",
    "fig, ax = plt.subplots(1, N_CHANNELS, figsize=(18,16), dpi=72, facecolor='w', edgecolor='k')\n",
    "if N_CHANNELS==1:\n",
    "    ax.axis('off')\n",
    "    ax.imshow(IMG[0,0,0,MID_SLICE,:,:], cmap=plt.cm.gray)\n",
    "else:\n",
    "    for channel in range(N_CHANNELS):\n",
    "        ax[channel].axis('off')\n",
    "        ax[channel].imshow(IMG[0,0,channel,MID_SLICE,:,:], cmap=plt.cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################\n",
    "structure_channel = 3\n",
    "#####################\n",
    "\n",
    "struct_img0 = IMG[0,0,structure_channel,:,:,:].copy()\n",
    "view(single_fluorescent_view(struct_img0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Pre-Processing\n",
    "\n",
    "About selected algorithms and tuned parameters\n",
    "\n",
    "* **Intensity normalization**: Parameter `intensity_scaling_param` has two options: two values, say `[A, B]`, or single value, say `[K]`. For the first case, `A` and `B` are non-negative values indicating that the full intensity range of the stack will first be cut-off into **[mean - A * std, mean + B * std]** and then rescaled to **[0, 1]**. The smaller the values of `A` and `B` are, the higher the contrast will be. For the second case, `K`>0 indicates min-max Normalization with an absolute intensity upper bound `K` (i.e., anything above `K` will be chopped off and reset as the minimum intensity of the stack) and `K`=0 means min-max Normalization without any intensity bound.\n",
    "\n",
    "    * Parameter for st6gal1:  `intensity_scaling_param = [9, 19]`\n",
    "\n",
    "\n",
    "* **Smoothing**: 3D gaussian smoothing with `gaussian_smoothing_sigma = 1`. The large the value is, the more the image will be smoothed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "## PARAMETER ##\n",
    "intensity_scaling_param = [9,19]\n",
    "gaussian_smoothing_sigma = 1\n",
    "################################\n",
    "# intensity normalization\n",
    "struct_img = intensity_normalization(struct_img0, scaling_param=intensity_scaling_param)\n",
    "\n",
    "# smoothing with gaussian filter\n",
    "structure_img_smooth = image_smoothing_gaussian_3d(struct_img, sigma=gaussian_smoothing_sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quickly visualize the image after smoothing\n",
    "view(single_fluorescent_view(structure_img_smooth))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If the contrast looks too off, you can tune the normalization parameters.\n",
    "\n",
    "We have a function to give you some suggestions. If you have certain preference, you can adjust the values based on the suggestion.\n",
    "\n",
    "***After you decide the parameters, you have to re-run the code above with the new parameter*** `intensity_scaling_param = ` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aicssegmentation.core.pre_processing_utils import suggest_normalization_param\n",
    "suggest_normalization_param(struct_img0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Core Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### step 2.1: Masked-Object (MO) Thresholding\n",
    "\n",
    "The basic idea of MO thresholding is to apply a relatively low global threshold to roughly mask out each individual object, and then apply a relatively high threshold within each object. This is meant to handle intensity variation from cell to cell. In general, triangle method and median method are two thresholding algorithms usually yield relatively low threshold. Otsu is used within each object for the relatively high threshold. \n",
    "\n",
    "* There are two parameters:\n",
    "    * `global_thresh_method`: Support `'tri'`, `'med'`,`'ave'` in current version. `'tri'` is triangle method, `'med'` is median method, `'ave'` is the average of the values returned by triangle method and median method.\n",
    "    * `object_minArea`: The minimal area of connected components after global thresholding to be considered as valid objects. Due to some background noise there could be some small connected components in the global thresholding result. Doing Otsu thresholding within such regions will certainly result in errors. So, we want remove them before doing thresholding within each object.  \n",
    "\n",
    "\n",
    "* Parameter for Sialyltransferase 1:  `global_thresh_method='tri'` and `object_minArea=1200`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bw, object_for_debug = MO(structure_img_smooth, global_thresh_method='tri', object_minArea=1200, return_object=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view the segmentation result\n",
    "viewer_bw = view(segmentation_quick_view(bw))\n",
    "viewer_bw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### After quickly visualizing the segmentation results, you can also visualize the segmentation and original image side by side\n",
    "##### You may select an ROI to inspect the details\n",
    "\n",
    "* Option 1: Easy ROI selection, but NOT recommended if you are using a laptop\n",
    "\n",
    "You can select an ROI in above visualization ('viewer_bw'); otherwise, the default ROI is the full image\n",
    "\n",
    "[See this video for How to select ROI](https://www.youtube.com/watch?v=ZO8ey6-tF_0&index=3&list=PL2lHcsoU0YJsh6f8j2vbhg2eEpUnKEWcl)\n",
    "\n",
    "* Option 2: Manually type in ROI coordinates\n",
    "\n",
    "Type in the coordinates of upper left corner and lower right corner of the ROI in the form of [Upper_Left_X, Upper_Left_Y, Lower_right_X, Lower_right_Y]. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1:\n",
    "view(seg_fluo_side_by_side(struct_img,bw,roi=['ROI',viewer_bw.roi_slice()]))\n",
    "\n",
    "# Option 2: \n",
    "# view(seg_fluo_side_by_side(struct_img,bw,roi=['M',[570,370,730,440]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### If the above segmentation is satisfactory? Here are some possible things to check:\n",
    "\n",
    "-------\n",
    "* Is there big missing chunk? Or are segmented chunks are significantly fatter? You may visualize the intermediate result, i.e. the objects, by `view(segmentation_quick_view(object_for_debug))`. By doing this, you can have some sense whether the objects are roughly regions in individual cells. In other words, we want to roughly isolate the stuffs in individual cells. If not, you may change `global_thresh_method`. Three options `'tri'`, `'med'`,`'ave'` are implemented. `'tri'` is triangle method, `'med'` is median method, `'ave'` is the average of the values returned by triangle method and median method. \n",
    "* Observing missing chunks may be also due to falsely removed objects. Try to decrease `object_minArea` to be more permisive in segmenting objects.\n",
    "* Do you observe a chunk of background stuffs in the segmentation? Try to increase `object_minArea` to exclude these background noise. \n",
    "* If you observe the segmented objects are slightly fatter than the actual size (may take defraction of light into consideration), don't worry, Next step (2.2) can help the make them thinner. \n",
    "* If you observe missing dots in the segmentation, don't worry. Later step (2.3) can pick them up.\n",
    "--------\n",
    "\n",
    "#### If the results are satisfactory, go to Step 2.2 directly; otherwise, try to tweak the parameters based on the above suggestions. \n",
    "\n",
    "Assumption: the segmentation result is saved in a variable named `bw`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2.2: Perform topology-preserving thinning \n",
    "There are two parameters:\n",
    "* `thin_dist_preserve`: Half of the minimum width you want to keep from being thinned. For example, when the object width is smaller than 4, you don't want to make this part even thinning (may break the thin object and alter the topology), you can set `thin_dist_preserve` as `2`.\n",
    "* `thin_dist`: the amount to thin (has to be an positive integer). The number of pixels to be removed from outter boundary towards center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thin_dist_preserve=1.6\n",
    "thin_dist=1\n",
    "bw_thin = topology_preserving_thinning(bw>0, thin_dist_preserve, thin_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer_thin = view(segmentation_quick_view(bw_thin))\n",
    "viewer_thin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1:\n",
    "view(seg_fluo_side_by_side(bw, bw_thin, roi=['ROI',viewer_thin.roi_slice()]))\n",
    "\n",
    "# Option 2: \n",
    "#view(seg_fluo_side_by_side(bw, bw_thin, roi=['M',[570,370,730,440]]))\n",
    "\n",
    "#left is the thinning result\n",
    "#right is the segmentation before thinning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### step 2.3: Apply 3D spot filter to detect extra spots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "## PARAMETERS for this step ##\n",
    "s3_param = [[1.6, 0.02]]\n",
    "################################\n",
    "\n",
    "bw_extra = dot_3d_wrapper(structure_img_smooth, s3_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer_extra = view(segmentation_quick_view(bw_extra))\n",
    "viewer_extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1:\n",
    "view(seg_fluo_side_by_side(struct_img,bw_extra,roi=['ROI',viewer_extra.roi_slice()]))\n",
    "\n",
    "# Option 2: \n",
    "# view(seg_fluo_side_by_side(struct_img,bw_extra,roi=['M',[570,370,730,440]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Is this step successfully picking up extra spots?\n",
    "\n",
    "Note: Your structure may or may not need this step to pickup extra spots. You may skip this step.\n",
    "\n",
    "----\n",
    "* Are the spots being detected? If not, try to reduce `cutoff_x`\n",
    "* Is there anything should not be detected but actually appear in the result? Try to increase `cutoff_x` or try a larger `scale_x`\n",
    "* Is the segmented size of the spots fatter than it should be? Try to increase `cutoff_x` or try a smaller `scale_x`\n",
    "* Is there any spot that should be solid but segmented as a ring? Try to increase `scale_x`\n",
    "* Are you observing spots with very different sizes? Try multiple sets of `scale_x` and `cutoff_x` \n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### step 2.4: Combine the MO segmentation and S3 segmentation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bw_combine = np.logical_or(bw_extra>0, bw_thin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Post-Processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "## PARAMETERS for this step ##\n",
    "minArea = 10\n",
    "################################\n",
    "\n",
    "seg = remove_small_objects(bw_combine>0, min_size=minArea, connectivity=1, in_place=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer_final = view(segmentation_quick_view(seg))\n",
    "viewer_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You can also focus your inspection on a small ROI\n",
    "\n",
    "* Option 1: Easy ROI selection, but NOT recommended if you are using a laptop\n",
    "\n",
    "You can select an ROI in above visualization ('viewer_final'); otherwise, the default ROI is the full image\n",
    "\n",
    "[See this video for How to select ROI](https://www.youtube.com/watch?v=ZO8ey6-tF_0&index=3&list=PL2lHcsoU0YJsh6f8j2vbhg2eEpUnKEWcl)\n",
    "\n",
    "* Option 2: Manually type in ROI coordinates\n",
    "\n",
    "Type in the coordinates of upper left corner and lower right corner of the ROI in the form of [Upper_Left_X, Upper_Left_Y, Lower_right_X, Lower_right_Y]. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: \n",
    "view(seg_fluo_side_by_side(struct_img, seg, roi=['ROI',viewer_final.roi_slice()]))\n",
    "\n",
    "# Option 2: \n",
    "# view(seg_fluo_side_by_side(struct_img, seg, roi=['M',[267,474, 468, 605]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You may also physically save the segmentation results into a .tiff image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg = seg >0\n",
    "out=seg.astype(np.uint8)\n",
    "out[out>0]=255\n",
    "writer = OmeTiffWriter('../../data/ST6GAL1/result/3500001289_100X_20170915_25_44_1-Scene-11-P39-E08_test_segmentation.tiff')\n",
    "writer.save(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
