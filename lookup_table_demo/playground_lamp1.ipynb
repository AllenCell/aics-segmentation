{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playground 5:  Segmentation workflow for LAMP-1\n",
    "\n",
    "This notebook contains the workflow for LAMP-1, and serves as a starting point for developing a classic segmentation workflow if your data shows similar morphology as LAMP-1.\n",
    "\n",
    "----------------------------------------\n",
    "\n",
    "Cell Structure Observations:\n",
    "\n",
    "* [LAMP-1](https://www.allencell.org/cell-observations/category/lamp1)\n",
    "\n",
    "----------------------------------------\n",
    "\n",
    "Key steps of the workflows:\n",
    "\n",
    "* Auto-Contrast intensity normalization\n",
    "* 2D Gaussian smoothing slice by slice\n",
    "* 2D Filament filter \n",
    "* 2D Spot filter \n",
    "* Hole filling\n",
    "* Size thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# package for 3d visualization\n",
    "from itkwidgets import view                              \n",
    "from aicssegmentation.core.visual import seg_fluo_side_by_side,  single_fluorescent_view, segmentation_quick_view\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = [16, 12]\n",
    "\n",
    "# package for io \n",
    "from aicsimageio import AICSImage\n",
    "from aicsimageio.writers import OmeTiffWriter\n",
    "\n",
    "# function for core algorithm\n",
    "from aicssegmentation.core.vessel import filament_2d_wrapper\n",
    "from aicssegmentation.core.seg_dot import dot_2d_slice_by_slice_wrapper\n",
    "from aicssegmentation.core.utils import hole_filling\n",
    "from aicssegmentation.core.pre_processing_utils import intensity_normalization, image_smoothing_gaussian_slice_by_slice\n",
    "from skimage.morphology import remove_small_objects, watershed, dilation, erosion, ball     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_NAME = '../../data/LAMP1/3500001519_100X_20171110_1-Scene-07-P21-E06.czi'\n",
    "\n",
    "reader = AICSImage(FILE_NAME) \n",
    "IMG = reader.data.astype(np.float32)\n",
    "\n",
    "print(IMG.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preview of the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_CHANNELS = IMG.shape[2]\n",
    "MID_SLICE = np.int(0.5*IMG.shape[3])\n",
    "\n",
    "fig, ax = plt.subplots(1, N_CHANNELS, figsize=(18,16), dpi=72, facecolor='w', edgecolor='k')\n",
    "if N_CHANNELS==1:\n",
    "    ax.axis('off')\n",
    "    ax.imshow(IMG[0,0,0,MID_SLICE,:,:], cmap=plt.cm.gray)\n",
    "else:\n",
    "    for channel in range(N_CHANNELS):\n",
    "        ax[channel].axis('off')\n",
    "        ax[channel].imshow(IMG[0,0,channel,MID_SLICE,:,:], cmap=plt.cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################\n",
    "structure_channel = 3\n",
    "#####################\n",
    "\n",
    "struct_img0 = IMG[0,0,structure_channel,:,:,:].copy()\n",
    "view(single_fluorescent_view(struct_img0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Pre-Processing\n",
    "\n",
    "About selected algorithms and tuned parameters\n",
    "\n",
    "* **Intensity normalization**: Parameter `intensity_scaling_param` has two options: two values, say `[A, B]`, or single value, say `[K]`. For the first case, `A` and `B` are non-negative values indicating that the full intensity range of the stack will first be cut-off into **[mean - A * std, mean + B * std]** and then rescaled to **[0, 1]**. The smaller the values of `A` and `B` are, the higher the contrast will be. For the second case, `K`>0 indicates min-max Normalization with an absolute intensity upper bound `K` (i.e., anything above `K` will be chopped off and reset as the minimum intensity of the stack) and `K`=0 means min-max Normalization without any intensity bound.\n",
    "\n",
    "    * Parameter for LAMP1:  `intensity_scaling_param = [9, 19]`\n",
    "\n",
    "\n",
    "* **Smoothing**:  2D gaussian smoothing slice by slice with `gaussian_smoothing_sigma = 1`. The large the value is, the more the image will be smoothed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "## PARAMETERS for this step ##\n",
    "intensity_scaling_param = [3, 19]\n",
    "gaussian_smoothing_sigma = 1\n",
    "################################\n",
    "# intensity normalization\n",
    "struct_img = intensity_normalization(struct_img0, scaling_param=intensity_scaling_param)\n",
    "\n",
    "# smoothing with 2d gaussian filter slice by slice \n",
    "structure_img_smooth = image_smoothing_gaussian_slice_by_slice(struct_img, sigma=gaussian_smoothing_sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view(single_fluorescent_view(structure_img_smooth))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If the contrast looks too off, you can tune the normalization parameters.\n",
    "\n",
    "We have a function to give you some suggestions. If you have certain preference, you can adjust the values based on the suggestion.\n",
    "\n",
    "***After you decide the parameters, you have to re-run the code above with the new parameter*** `intensity_scaling_param = ` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aicssegmentation.core.pre_processing_utils import suggest_normalization_param\n",
    "suggest_normalization_param(struct_img0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Core Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### step 2.1: Apply 2D spot filter slice by slice to detect spots\n",
    "\n",
    "Parameter syntax: `[[scale_1, cutoff_1], [scale_2, cutoff_2], ....]` \n",
    "* `scale_x` is set based on the estimated radius of your target spotty shape. For example, if visually the diameter of the spotty objects is usually 3~4 pixels, then you may want to set `scale_x` as `1` or something near `1` (like `1.25`). Multiple scales can be used, if you have objects of very different sizes.  \n",
    "* `cutoff_x` is a threshold applied on the actual filter reponse to get the binary result. Smaller `cutoff_x` may yielf fatter segmentation, while larger `cutoff_x` could be less permisive and yield less objects and slimmer segmentation. \n",
    "\n",
    "Parameter for LAMP1:  `s2_param =[[5,0.09], [2.5,0.07], [1,0.01]]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "## PARAMETERS for this step ##\n",
    "s2_param = [[5,0.09], [2.5,0.07], [1,0.01]]\n",
    "################################\n",
    "\n",
    "bw_spot = dot_2d_slice_by_slice_wrapper(structure_img_smooth, s2_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer_bw_spot = view(segmentation_quick_view(bw_spot))\n",
    "viewer_bw_spot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### After quickly visualizing the segmentation results, you can also visualize the segmentation and original image side by side\n",
    "##### You may select an ROI to inspect the details\n",
    "\n",
    "* Option 1: Easy ROI selection, but NOT recommended if you are using a laptop\n",
    "\n",
    "You can select an ROI in above visualization ('viewer_bw_spot'); otherwise, the default ROI is the full image\n",
    "\n",
    "[See this video for How to select ROI](https://www.youtube.com/watch?v=ZO8ey6-tF_0&index=3&list=PL2lHcsoU0YJsh6f8j2vbhg2eEpUnKEWcl)\n",
    "\n",
    "* Option 2: Manually type in ROI coordinates\n",
    "\n",
    "Type in the coordinates of upper left corner and lower right corner of the ROI in the form of [Upper_Left_X, Upper_Left_Y, Lower_right_X, Lower_right_Y]. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1:\n",
    "view(seg_fluo_side_by_side(struct_img,bw_spot,roi=['ROI',viewer_bw_spot.roi_slice()]))\n",
    "\n",
    "# Option 2: \n",
    "# view(seg_fluo_side_by_side(struct_img,bw_spot,roi=['M',[570,370,730,440]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Is the segmentation satisfactory? Here are some possible criteria:\n",
    "\n",
    "--------------------\n",
    "* Is there any spot should be detected but not? Try to reduce `cutoff_x`\n",
    "* Is there any object should not be detected but actually appear in the result? Try to increase `cutoff_x` or try a larger `scale_x`\n",
    "* Is the segmented size of the spots fatter than it should be? Try to increase `cutoff_x` or try a smaller `scale_x`\n",
    "* Is there any spot that should be solid but segmented as a ring? Try to increase `scale_x`\n",
    "* Are you observing spots with very different sizes? Try multiple sets of `scale_x` and `cutoff_x` \n",
    "------------------------\n",
    "\n",
    "**If good, go to step 2.2**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### step 2.2: Apply 2D filament filter slice by slice to filaments\n",
    "\n",
    "Parameter syntax: `[[scale_1, cutoff_1], [scale_2, cutoff_2], ....]` \n",
    "* `scale_x` is set based on the estimated width of your target curvilinear shape. For example, if visually the width of the objects is usually 3~4 pixels, then you may want to set `scale_x` as `1` or something near `1` (like `1.25`). Multiple scales can be used, if you have objects of very different sizes.  \n",
    "* `cutoff_x` is a threshold applied on the actual filter reponse to get the binary result. Smaller `cutoff_x` may yielf fatter segmentation, while larger `cutoff_x` could be less permisive and yield less objects and slimmer segmentation. \n",
    "\n",
    "Parameter for LAMP1:  `f2_param = [[1, 0.15]]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "## PARAMETERS for this step ##\n",
    "f2_param = [[1, 0.15]]\n",
    "################################\n",
    "\n",
    "bw_filament = filament_2d_wrapper(structure_img_smooth, f2_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view(segmentation_quick_view(bw_filament))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Is the segmentation satisfactory? Here are some possible criteria:\n",
    "\n",
    "----------------\n",
    "* Is there any object should be detected but not? Try to reduce `cutoff_x`\n",
    "* Is there any object should not be detected but actually appear in the result? Try to increase `cutoff_x` or try a larger `scale_x`\n",
    "* Is the segmented width of the objects is fatter than it should be? Try to increase `cutoff_x` or try a smaller `scale_x`\n",
    "* Is there any object that should be solid but segmented as fragmented pieces? Try to increase `scale_x`\n",
    "* Are you observing objects with very different width? Try multiple sets of `scale_x` and `cutoff_x` \n",
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### step 2.3: merge the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bw = np.logical_or(bw_spot, bw_filament)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Post-Processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "## PARAMETERS for this step ##\n",
    "fill_2d = True\n",
    "fill_max_size = 1600\n",
    "minArea = 15\n",
    "################################\n",
    "\n",
    "bw_fill = hole_filling(bw, 0, fill_max_size, fill_2d)\n",
    "\n",
    "seg = remove_small_objects(bw_fill>0, min_size=minArea, connectivity=1, in_place=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer_final = view(segmentation_quick_view(seg))\n",
    "viewer_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You can also focus your inspection on a small ROI\n",
    "\n",
    "* Option 1: Easy ROI selection, but NOT recommended if you are using a laptop\n",
    "\n",
    "You can select an ROI in above visualization ('viewer_final'); otherwise, the default ROI is the full image\n",
    "\n",
    "[See this video for How to select ROI](https://www.youtube.com/watch?v=ZO8ey6-tF_0&index=3&list=PL2lHcsoU0YJsh6f8j2vbhg2eEpUnKEWcl)\n",
    "\n",
    "* Option 2: Manually type in ROI coordinates\n",
    "\n",
    "Type in the coordinates of upper left corner and lower right corner of the ROI in the form of [Upper_Left_X, Upper_Left_Y, Lower_right_X, Lower_right_Y]. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: \n",
    "view(seg_fluo_side_by_side(struct_img, seg, roi=['ROI',viewer_final.roi_slice()]))\n",
    "\n",
    "# Option 2: \n",
    "#view(seg_fluo_side_by_side(struct_img, seg, roi=['M',[267,474, 468, 605]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You may also physically save the segmentation results into a ome.tif file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg = seg >0\n",
    "out=seg.astype(np.uint8)\n",
    "out[out>0]=255\n",
    "writer = OmeTiffWriter('../../data/LAMP1/result/test_segmentation.tiff')\n",
    "writer.save(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
