{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playground 6:  Segmentation workflows for \"dots\"-like structures\n",
    "\n",
    "This notebook contains the workflows for Centrin-2, Desmoplakin, and PMP34, and serves as a starting point for developing a classic segmentation workflow for your data with dots-like shapes.\n",
    "\n",
    "----------------------------------------\n",
    "\n",
    "Cell Structure Observations:\n",
    "\n",
    "* [Centrin-2](https://www.allencell.org/cell-observations/category/centrin)\n",
    "\n",
    "* [Desmoplakin](https://www.allencell.org/cell-observations/category/desmoplakin)\n",
    "\n",
    "* [PMP34](https://www.allencell.org/cell-observations/category/pmp34)\n",
    "\n",
    "----------------------------------------\n",
    "\n",
    "Key steps of the workflows:\n",
    "\n",
    "* Min-max intensity normalization\n",
    "* 2D Gaussian smoothing (slice-by-slice)\n",
    "* 3D spot filter to detect dots\n",
    "* Watershed for seperating falsely merged dots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# package for 3d visualization\n",
    "from itkwidgets import view                              \n",
    "from aicssegmentation.core.visual import seg_fluo_side_by_side,  single_fluorescent_view, segmentation_quick_view\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = [16, 12]\n",
    "\n",
    "# package for io \n",
    "from aicsimageio import AICSImage\n",
    "from aicsimageio.writers import OmeTiffWriter\n",
    "\n",
    "# function for core algorithm\n",
    "from aicssegmentation.core.seg_dot import dot_3d, dot_3d_wrapper \n",
    "from aicssegmentation.core.pre_processing_utils import intensity_normalization, image_smoothing_gaussian_slice_by_slice\n",
    "from skimage.morphology import remove_small_objects,  dilation, erosion, ball     # function for post-processing (size filter)\n",
    "from skimage.segmentation import watershed\n",
    "\n",
    "from aicssegmentation.core.utils import peak_local_max_wrapper\n",
    "from skimage.measure import label\n",
    "from scipy.ndimage import distance_transform_edt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_NAME = '../../data/CETN2/original/3500001610_100X_20180112_1-Scene-10-P30-F05.czi'\n",
    "\n",
    "reader = AICSImage(FILE_NAME) \n",
    "IMG = reader.data.astype(np.float32)\n",
    "\n",
    "print(IMG.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preview of the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_CHANNELS = IMG.shape[2]\n",
    "MID_SLICE = np.int(0.5*IMG.shape[3])\n",
    "\n",
    "fig, ax = plt.subplots(1, N_CHANNELS, figsize=(18,16), dpi=72, facecolor='w', edgecolor='k')\n",
    "if N_CHANNELS==1:\n",
    "    ax.axis('off')\n",
    "    ax.imshow(IMG[0,0,0,MID_SLICE,:,:], cmap=plt.cm.gray)\n",
    "else:\n",
    "    for channel in range(N_CHANNELS):\n",
    "        ax[channel].axis('off')\n",
    "        ax[channel].imshow(IMG[0,0,channel,MID_SLICE,:,:], cmap=plt.cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################\n",
    "structure_channel = 3\n",
    "#####################\n",
    "\n",
    "struct_img0 = IMG[0,0,structure_channel,:,:,:].copy()\n",
    "view(single_fluorescent_view(struct_img0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Pre-Processing\n",
    "\n",
    "About selected algorithms and tuned parameters\n",
    "\n",
    "* **Intensity normalization**: Parameter `intensity_scaling_param` has two options: two values, say `[A, B]`, or single value, say `[K]`. For the first case, `A` and `B` are non-negative values indicating that the full intensity range of the stack will first be cut-off into **[mean - A * std, mean + B * std]** and then rescaled to **[0, 1]**. The smaller the values of `A` and `B` are, the higher the contrast will be. For the second case, `K`>0 indicates min-max Normalization with an absolute intensity upper bound `K` (i.e., anything above `K` will be chopped off and reset as the minimum intensity of the stack) and `K`=0 means min-max Normalization without any intensity bound.\n",
    "\n",
    "    * Parameter for Centrin-2:  `intensity_scaling_param = [8000]`\n",
    "    * Parameter for Desmoplakin:  `intensity_scaling_param = [8000]`\n",
    "    * Parameter for PMP34:  `intensity_scaling_param = [6000]`\n",
    "\n",
    "These three all use Min-Max Normalization, just with slightly different absolute intensity upper bound. Using Min-Max normalization is meant to keep the full intensity profile near the brightest area, usually the center of the \"balls\" as in these structures. Such bright centers are important for the success of these workflows. Meanwhile, adding an absolute intensity upper bound is meant to be robust to imaging artifacts, like dead pixels. If there is one dead pixel in an image stack with extremely high intensity (way out of normal intensity range), the Min-Max normalization will squeeze the value of actual structures into a tiny range close to 0. So, we add an upper bound. For example, in Centrin-2, if a pixel has intensity value over 8000, this pixel will be treated as an outlier and reset as the minimum intensity of the stack. \n",
    "\n",
    "* **Smoothing** \n",
    "\n",
    "These three all use 2D gaussian smoothing with `gaussian_smoothing_sigma = 1`. Usually, 3D gaussian is used by default. But, here we apply 2D gaussian slice by slice, because when we do live imaging, these \"ball\"-shape structures could move visible amount (considering these \"balls\" themselves are tiny) during the time interval between two consecutive z slices. So, 3D guassian smoothing may further aggravate the subtle shift in consecutive z-slices. If your data do not have such problem, you can certainly try 3D gaussian by `image_smoothing_gaussian_3d(struct_img, sigma=gaussian_smoothing_sigma)` with `gaussian_smoothing_sigma = 1`. To deal with very noisy data, you may consider increase `gaussian_smoothing_sigma` from 1 to a higher value, like 1.5 or 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "intensity_scaling_param = [8000]\n",
    "gaussian_smoothing_sigma = 1\n",
    "################################\n",
    "\n",
    "# intensity normalization\n",
    "struct_img = intensity_normalization(struct_img0, scaling_param=intensity_scaling_param)\n",
    "\n",
    "# smoothing with gaussian filter\n",
    "structure_img_smooth = image_smoothing_gaussian_slice_by_slice(struct_img, sigma=gaussian_smoothing_sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quickly visualize the image after smoothing\n",
    "view(single_fluorescent_view(structure_img_smooth))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Core Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### step 2.1: Apply 3D Spot filter (S3)\n",
    "\n",
    "* Parameter syntax: `[[scale_1, cutoff_1], [scale_2, cutoff_2], ....]` \n",
    "    * `scale_x` is set based on the estimated radius of your target dots. For example, if visually the diameter of the dots is usually 3~4 pixels, then you may want to set `scale_x` as `1` or something near `1` (like `1.25`). Multiple scales can be used, if you have dots of very different sizes.  \n",
    "    * `cutoff_x` is a threshold applied on the actual filter reponse to get the binary result. Smaller `cutoff_x` may yielf more dots and fatter segmentation, while larger `cutoff_x` could be less permisive and yield less dots and slimmer segmentation. \n",
    "\n",
    "* Parameter for Centrin-2:  `s3_param = [[1, 0.04]]`\n",
    "\n",
    "* Parameter for Desmoplakin:  `s3_param = [[1, 0.012]]`\n",
    "\n",
    "* Parameter for PMP34:  `s3_param = [[1,0.03]]`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "## PARAMETERS for this step ##\n",
    "s3_param = [[1, 0.04]]\n",
    "################################\n",
    "\n",
    "bw = dot_3d_wrapper(structure_img_smooth, s3_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view the segmentation result\n",
    "viewer_bw = view(segmentation_quick_view(bw))\n",
    "viewer_bw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### After quickly visualizing the segmentation results, you can also visualize the segmentation and original image side by side\n",
    "##### You may select an ROI to inspect the details\n",
    "\n",
    "* Option 1: Easy ROI selection, but NOT recommended if you are using a laptop\n",
    "\n",
    "You can select an ROI in above visualization ('viewer_bw'); otherwise, the default ROI is the full image\n",
    "\n",
    "[See this video for How to select ROI](https://www.youtube.com/watch?v=ZO8ey6-tF_0&index=3&list=PL2lHcsoU0YJsh6f8j2vbhg2eEpUnKEWcl)\n",
    "\n",
    "* Option 2: Manually type in ROI coordinates\n",
    "\n",
    "Type in the coordinates of upper left corner and lower right corner of the ROI in the form of [Upper_Left_X, Upper_Left_Y, Lower_right_X, Lower_right_Y]. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1:\n",
    "view(seg_fluo_side_by_side(struct_img,bw,roi=['ROI',viewer_bw.roi_slice()]))\n",
    "\n",
    "# Option 2: \n",
    "# view(seg_fluo_side_by_side(struct_img,bw,roi=['M',[570,370,730,440]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Is the segmentation satisfactory? Here are some possible criteria:\n",
    "\n",
    "--------------------------\n",
    "* Note: next step (2.2) can further cut falsely merged spots.\n",
    "* Is there any spot should be detected but not? Try to reduce `cutoff_x`\n",
    "* Is there any spot should not be detected but actually appear in the result? Try to increase `cutoff_x` or try a larger `scale_x`\n",
    "* Is the segmented size of the spots fatter than it should be? Try to increase `cutoff_x` or try a smaller `scale_x`\n",
    "* Is there any spot that should be solid but segmented as a ring? Try to increase `scale_x`\n",
    "* Are you observing spots with very different sizes? Try multiple sets of `scale_x` and `cutoff_x` \n",
    "--------------------------\n",
    "\n",
    "#### If the results are satisfactory, go to Step 2.2 directly; otherwise, try to tweak the parameters based on the above suggestions. \n",
    "\n",
    "Assumption: the segmentation result is saved in a variable named `bw`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2.2: Watershed for cutting falsely merged spots\n",
    "\n",
    "This step may take 2~3 minutes or longer, depending on the number of dots in your images. \n",
    "\n",
    "In general, no parameter tuning is needed in this step. The only parameter is `minArea=4`, which is the parameter for size thresholding in post-processing. In practice, when we know an object whose size is smaller than `minArea` will be removed eventually, we can just remove them before doing watershed to cut falsely merged cells. This is only meant to avoid unnecessary computation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# watershed\n",
    "minArea = 4\n",
    "Mask = remove_small_objects(bw>0, min_size=minArea, connectivity=1, in_place=False) \n",
    "Seed = dilation(peak_local_max_wrapper(struct_img,label(Mask)), selem=ball(1))\n",
    "Watershed_Map = -1*distance_transform_edt(bw)\n",
    "seg = watershed(Watershed_Map, label(Seed), mask=Mask, watershed_line=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Post-Processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "## PARAMETERS for this step ##\n",
    "minArea = 4 \n",
    "################################\n",
    "\n",
    "seg = remove_small_objects(seg>0, min_size=minArea, connectivity=1, in_place=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer_final = view(segmentation_quick_view(seg))\n",
    "viewer_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You can also focus your inspection on a small ROI\n",
    "\n",
    "* Option 1: Easy ROI selection, but NOT recommended if you are using a laptop\n",
    "\n",
    "You can select an ROI in above visualization ('viewer_final'); otherwise, the default ROI is the full image\n",
    "\n",
    "[See this video for How to select ROI](https://www.youtube.com/watch?v=ZO8ey6-tF_0&index=3&list=PL2lHcsoU0YJsh6f8j2vbhg2eEpUnKEWcl)\n",
    "\n",
    "* Option 2: Manually type in ROI coordinates\n",
    "\n",
    "Type in the coordinates of upper left corner and lower right corner of the ROI in the form of [Upper_Left_X, Upper_Left_Y, Lower_right_X, Lower_right_Y]. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: \n",
    "view(seg_fluo_side_by_side(struct_img, seg, roi=['ROI',viewer_final.roi_slice()]))\n",
    "\n",
    "# Option 2: \n",
    "#view(seg_fluo_side_by_side(struct_img, seg, roi=['M',[267,474, 468, 605]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You can also inspect the same ROI on the effect of final cutting step (the same ROI as above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1 for ROI selection:\n",
    "view(seg_fluo_side_by_side(bw, seg, roi=['ROI',viewer_final.roi_slice()]))\n",
    "\n",
    "# Option 2 for ROI selection:\n",
    "#view(seg_fluo_side_by_side(bw, seg, roi=['M',[570,370,730,440]]))\n",
    "# left is the final version\n",
    "# right is the version before cutting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You may also physically save the segmentation results into a .tiff image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg = seg >0\n",
    "out=seg.astype(np.uint8)\n",
    "out[out>0]=255\n",
    "writer = OmeTiffWriter('../../data/CETN2/result/3500001610_100X_20180112_1-Scene-10-P30-F05_test_segmentation.tiff')\n",
    "writer.save(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
